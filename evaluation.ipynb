{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: API details.\n",
    "output-file: evaluation.html\n",
    "title: evaluation\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from wxbs_benchmark.dataset import *\n",
    "from wxbs_benchmark.metrics import *\n",
    "\n",
    "def evaluate_Fs(Fs = [], subset = 'test'):\n",
    "    dset = WxBSDataset('.WxBS', subset=subset, download=True)\n",
    "    ths = np.arange(20)\n",
    "    gt_corrs = []\n",
    "    names = []\n",
    "    for data_dict in dset:\n",
    "        corrs = data_dict['pts']\n",
    "        pairname = data_dict['name']\n",
    "        names.append(pairname)\n",
    "        gt_corrs.append(corrs)\n",
    "    assert len(Fs) == len(gt_corrs)\n",
    "    per_pair_results = {}\n",
    "    all_res = []\n",
    "    for (F, pts, pairname) in zip(Fs, gt_corrs, names):\n",
    "        res = fraction_of_gt_corrs_consisent_with_F(F, pts, ths)\n",
    "        per_pair_results[pairname] = res\n",
    "        all_res.append(res)\n",
    "    per_pair_results['average'] = np.stack(all_res, axis=1).mean(axis=1)\n",
    "    return per_pair_results, ths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluates fundamental matrices returned by algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WGABS/petrzin': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.05263158, 0.05263158], 'WGALBS/kyiv_dolltheater2': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'average': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.01315789, 0.01315789,\n",
      "       0.01315789, 0.01315789, 0.01315789, 0.02631579, 0.02631579],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "shift_f = np.array([[0.0, 0.0, 0.0],\n",
    "              [0.0, 0.0, -1.0],\n",
    "              [0.0, 1.0, 0.0]])\n",
    "Fs = [shift_f, shift_f]\n",
    "\n",
    "res_dict, th = evaluate_Fs(Fs, 'val')\n",
    "print (res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_corrs(estimated_right = [],\n",
    "                   estimated_left = [],\n",
    "                   subset = 'test'):\n",
    "    dset = WxBSDataset('.WxBS', subset=subset, download=True)\n",
    "    ths = np.arange(20)\n",
    "    gt_corrs = []\n",
    "    names = []\n",
    "    for data_dict in dset:\n",
    "        corrs = data_dict['pts']\n",
    "        pairname = data_dict['name']\n",
    "        names.append(pairname)\n",
    "        gt_corrs.append(corrs)\n",
    "    assert len(estimated_right) == len(gt_corrs)\n",
    "    assert len(estimated_left) == len(gt_corrs)\n",
    "    all_res = []\n",
    "    per_pair_results = {}\n",
    "    for (est_right, est_left, gt_pts, pairname) in zip(estimated_right,\n",
    "                                                       estimated_left, \n",
    "                                                       gt_corrs, names):\n",
    "        res = 0.5 * (PCK(est_right, gt_pts[:, 2:4], ths) + \n",
    "                     PCK(est_left,  gt_pts[:, :2], ths))\n",
    "        per_pair_results[pairname] = res\n",
    "        all_res.append(res)\n",
    "    per_pair_results['average'] = np.stack(all_res, axis=1).mean(axis=1)\n",
    "    return per_pair_results, ths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check the naive baseline -- no camera motion, return the input baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'WGABS/petrzin': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32), 'WGALBS/kyiv_dolltheater2': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32), 'average': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32)}, array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19]))\n"
     ]
    }
   ],
   "source": [
    "dset = WxBSDataset('.WxBS', subset='val', download=True)\n",
    "predicted_left = []\n",
    "predicted_right = []\n",
    "for res_dict in dset:\n",
    "    gt_corrs = res_dict['pts']\n",
    "    query_left = gt_corrs[:, :2]\n",
    "    query_right = gt_corrs[:, 2:]\n",
    "    predicted_right.append(query_left)\n",
    "    predicted_left.append(query_right)\n",
    "eval_results = evaluate_corrs (predicted_right, predicted_left, subset='val')\n",
    "print (eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_Hs(Hs = []):\n",
    "    dset = EVDDataset('.EVD', download=True)\n",
    "    ths = np.logspace(np.log2(1.0), np.log2(20), 10, base=2.0)\n",
    "    gt_homos = []\n",
    "    names = []\n",
    "    shapes1 = []\n",
    "    shapes2 = []\n",
    "    \n",
    "    for data_dict in dset:\n",
    "        gt_homo = data_dict['H']\n",
    "        pairname = data_dict['name']\n",
    "        shapes1.append(data_dict['img1_shape'])\n",
    "        shapes2.append(data_dict['img2_shape'])\n",
    "        names.append(pairname)\n",
    "        gt_homos.append(gt_homo)\n",
    "    assert len(Hs) == len(gt_homos)\n",
    "    per_pair_results = {}\n",
    "    all_res = []\n",
    "    for (H, Hgt, sh1, sh2, pairname) in zip(Hs, gt_homos, shapes1, shapes2, names):\n",
    "        mae = get_visible_part_mean_absolute_reprojection_error(sh1, sh2, Hgt, H)\n",
    "        per_pair_results[pairname] = mae\n",
    "        all_res.append(mae)\n",
    "        \n",
    "    per_pair_results['average'] = get_mAA(all_res, ths)\n",
    "    return per_pair_results, ths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'adam': 0.0, 'cafe': 0.0, 'cat': 0.0, 'dum': 0.0, 'face': 0.0, 'fox': 0.0, 'girl': 0.0, 'graf': 0.0, 'grand': 0.0, 'index': 0.0, 'mag': 0.0, 'pkk': 0.0, 'shop': 0.0, 'there': 0.0, 'vin': 0.0, 'average': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, array([ 1.        ,  1.39495079,  1.94588772,  2.71441762,  3.78647901,\n",
      "        5.2819519 ,  7.368063  , 10.27808533, 14.33742329, 20.        ]))\n"
     ]
    }
   ],
   "source": [
    "dset = EVDDataset('.EVD', download=True)\n",
    "predicted_Hs = []\n",
    "for res_dict in dset:\n",
    "    gt_H = res_dict['H']\n",
    "    predicted_Hs.append(gt_H)\n",
    "eval_results = evaluate_Hs (predicted_Hs)\n",
    "print (eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
