{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import os\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class WxBSDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Wide multiple baselines stereo dataset.\"\"\"\n",
    "    urls = {\n",
    "        'v1.1': [\n",
    "            'http://cmp.felk.cvut.cz/wbs/datasets/WxBS_v1.1.zip',\n",
    "            'WxBS_v1.1.zip',\n",
    "            '66da037e7d20487e86db147307615870'\n",
    "        ]}\n",
    "    validation_pairs = ['kyiv_dolltheater2', 'petrzin']\n",
    "                        \n",
    "    def __init__(self, root_dir:str, subset: str = 'test',  version='v1.1', download: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            subset (string): can be \"val\" or \"test\".\n",
    "            download (bool): download if not found, default: False\n",
    "        \"\"\"\n",
    "        assert version in self.urls.keys()\n",
    "        self.root_dir = root_dir\n",
    "        self.subset = subset\n",
    "        self.validation_mode = self.subset == 'val'\n",
    "        self.version = version\n",
    "        self.data_dir = os.path.join(self.root_dir, version)\n",
    "        self.data_down = os.path.join(self.root_dir, '{}.zip'.format(version))\n",
    "        if not self._check_unpacked():\n",
    "            if download:\n",
    "                self.download()\n",
    "            else:\n",
    "                raise ValueError(f'Data is not in {self.data_dir}, consider set download=True')\n",
    "        self.index_dataset()\n",
    "        return\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def _check_downloaded(self):\n",
    "        if os.path.exists(self.data_down):\n",
    "            import hashlib\n",
    "            md5 = hashlib.md5(self.data_down).hexdigest()\n",
    "            if md5 == self.urls[self.version][2]:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _check_unpacked(self):\n",
    "        return os.path.exists(self.data_dir)\n",
    "\n",
    "    def download(self) -> None:\n",
    "        if not self._check_downloaded():\n",
    "            # download files\n",
    "            url = self.urls[self.version][0]\n",
    "            filename = self.urls[self.version][1]\n",
    "            md5 = self.urls[self.version][2]\n",
    "            fpath = os.path.join(self.root_dir, filename)\n",
    "            tv.datasets.phototour.download_url(url, self.root_dir, filename, md5)\n",
    "            print('# Extracting data {}\\n'.format(self.data_down))\n",
    "            import zipfile\n",
    "            with zipfile.ZipFile(fpath, 'r') as z:\n",
    "                z.extractall(self.data_dir)\n",
    "            os.unlink(fpath)\n",
    "        return\n",
    "\n",
    "    def index_dataset(self):\n",
    "        sets = sorted([x for x in os.listdir(self.data_dir) if os.path.isdir(os.path.join(self.data_dir, x))])\n",
    "        img_pairs_list = []\n",
    "        for s in sets:\n",
    "            if s == '.DS_Store':\n",
    "                continue\n",
    "            ss = os.path.join(self.data_dir, s)\n",
    "            pairs = os.listdir(ss)\n",
    "            for p in sorted(pairs):\n",
    "                if p == '.DS_Store':\n",
    "                    continue\n",
    "                cur_dir = os.path.join(ss, p)\n",
    "                if self.validation_mode:\n",
    "                    if p not in self.validation_pairs:\n",
    "                        continue\n",
    "                else:\n",
    "                    if p in self.validation_pairs:\n",
    "                        continue\n",
    "                if os.path.isfile(os.path.join(cur_dir, '01.png')):\n",
    "                    img_pairs_list.append((os.path.join(cur_dir, '01.png'),\n",
    "                                           os.path.join(cur_dir, '02.png'),\n",
    "                                           os.path.join(cur_dir, 'corrs.txt'),\n",
    "                                           os.path.join(cur_dir, 'crossval_errors.txt')))\n",
    "                elif os.path.isfile(os.path.join(cur_dir, '01.jpg')):\n",
    "                    img_pairs_list.append((os.path.join(cur_dir, '01.jpg'),\n",
    "                                           os.path.join(cur_dir, '02.jpg'),\n",
    "                                           os.path.join(cur_dir, 'corrs.txt'),\n",
    "                                           os.path.join(cur_dir, 'crossval_errors.txt')))\n",
    "                else:\n",
    "                    continue\n",
    "        self.pairs = img_pairs_list\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imgfname1, imgfname2, pts_fname, err_fname = self.pairs[idx]\n",
    "        img1 = np.array(Image.open(imgfname1))\n",
    "        img2 = np.array(Image.open(imgfname2))\n",
    "        pts = np.loadtxt(pts_fname)\n",
    "        crossval_errors = np.loadtxt(err_fname)\n",
    "        pair_name = '/'.join(pts_fname.split('/')[-3:-1])\n",
    "        out = {'img1': img1,\n",
    "               'img2': img2,\n",
    "               'pts': pts,\n",
    "               'errors': crossval_errors,\n",
    "               'name': pair_name}\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset returns tuples of: image1, image2, labelled GT correspondences, cross-validation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['img1', 'img2', 'pts', 'errors', 'name'])\n",
      "WGABS/kremlin\n"
     ]
    }
   ],
   "source": [
    "dset = WxBSDataset('.WXBS', download=True)\n",
    "print (dset[0].keys())\n",
    "print (dset[0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
